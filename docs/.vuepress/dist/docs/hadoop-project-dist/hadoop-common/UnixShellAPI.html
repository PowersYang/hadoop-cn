<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Hadoop中文网</title>
    <meta name="description" content="Hadoop官方文档中文社区">
    <link rel="icon" href="/hadoop.jpeg">
    
    <link rel="preload" href="/assets/css/0.styles.299736e7.css" as="style"><link rel="preload" href="/assets/js/app.44e5c4e8.js" as="script"><link rel="preload" href="/assets/js/2.fd33e103.js" as="script"><link rel="preload" href="/assets/js/51.6c32c16e.js" as="script"><link rel="prefetch" href="/assets/js/10.0dbc29ee.js"><link rel="prefetch" href="/assets/js/100.51e7458e.js"><link rel="prefetch" href="/assets/js/101.cab336f3.js"><link rel="prefetch" href="/assets/js/102.d7e40b1a.js"><link rel="prefetch" href="/assets/js/103.3cd23502.js"><link rel="prefetch" href="/assets/js/104.a263cbd3.js"><link rel="prefetch" href="/assets/js/105.1cf856b7.js"><link rel="prefetch" href="/assets/js/106.1bd66c2f.js"><link rel="prefetch" href="/assets/js/107.7acc52af.js"><link rel="prefetch" href="/assets/js/108.096bf626.js"><link rel="prefetch" href="/assets/js/109.91d5ec0d.js"><link rel="prefetch" href="/assets/js/11.84130fe4.js"><link rel="prefetch" href="/assets/js/110.602bc28b.js"><link rel="prefetch" href="/assets/js/111.531e373d.js"><link rel="prefetch" href="/assets/js/112.dcdb6f77.js"><link rel="prefetch" href="/assets/js/113.7519fa7c.js"><link rel="prefetch" href="/assets/js/114.97ce2cfb.js"><link rel="prefetch" href="/assets/js/115.719819cf.js"><link rel="prefetch" href="/assets/js/116.606be43b.js"><link rel="prefetch" href="/assets/js/117.5f1db751.js"><link rel="prefetch" href="/assets/js/118.4c8b3331.js"><link rel="prefetch" href="/assets/js/119.756df93e.js"><link rel="prefetch" href="/assets/js/12.a85df2ad.js"><link rel="prefetch" href="/assets/js/120.9735cc8b.js"><link rel="prefetch" href="/assets/js/121.de0f88c2.js"><link rel="prefetch" href="/assets/js/122.68c84b42.js"><link rel="prefetch" href="/assets/js/123.26f2d157.js"><link rel="prefetch" href="/assets/js/124.b8bb5eac.js"><link rel="prefetch" href="/assets/js/125.d3748b6f.js"><link rel="prefetch" href="/assets/js/126.74a59909.js"><link rel="prefetch" href="/assets/js/127.e75ea051.js"><link rel="prefetch" href="/assets/js/128.86691d41.js"><link rel="prefetch" href="/assets/js/129.1b73844b.js"><link rel="prefetch" href="/assets/js/13.5cc92b07.js"><link rel="prefetch" href="/assets/js/14.23af424b.js"><link rel="prefetch" href="/assets/js/15.d44d7e96.js"><link rel="prefetch" href="/assets/js/16.9433ad8d.js"><link rel="prefetch" href="/assets/js/17.e88b2671.js"><link rel="prefetch" href="/assets/js/18.621a61a9.js"><link rel="prefetch" href="/assets/js/19.c2269943.js"><link rel="prefetch" href="/assets/js/20.97a13073.js"><link rel="prefetch" href="/assets/js/21.cfddb2e0.js"><link rel="prefetch" href="/assets/js/22.3fc2e173.js"><link rel="prefetch" href="/assets/js/23.b44f9aaa.js"><link rel="prefetch" href="/assets/js/24.5118c903.js"><link rel="prefetch" href="/assets/js/25.d075e5d7.js"><link rel="prefetch" href="/assets/js/26.773f2460.js"><link rel="prefetch" href="/assets/js/27.d0e0d308.js"><link rel="prefetch" href="/assets/js/28.bba4c1c3.js"><link rel="prefetch" href="/assets/js/29.0d309c43.js"><link rel="prefetch" href="/assets/js/3.df8ab865.js"><link rel="prefetch" href="/assets/js/30.dc22d7ad.js"><link rel="prefetch" href="/assets/js/31.f4f5b282.js"><link rel="prefetch" href="/assets/js/32.126829f0.js"><link rel="prefetch" href="/assets/js/33.b7210392.js"><link rel="prefetch" href="/assets/js/34.808d7f11.js"><link rel="prefetch" href="/assets/js/35.92cc0670.js"><link rel="prefetch" href="/assets/js/36.525eca62.js"><link rel="prefetch" href="/assets/js/37.085ca99e.js"><link rel="prefetch" href="/assets/js/38.bd6ba530.js"><link rel="prefetch" href="/assets/js/39.bdcf0246.js"><link rel="prefetch" href="/assets/js/4.03a382ed.js"><link rel="prefetch" href="/assets/js/40.0a881a26.js"><link rel="prefetch" href="/assets/js/41.e2d38f86.js"><link rel="prefetch" href="/assets/js/42.d3be59ab.js"><link rel="prefetch" href="/assets/js/43.861403a7.js"><link rel="prefetch" href="/assets/js/44.64ea788c.js"><link rel="prefetch" href="/assets/js/45.586e01c2.js"><link rel="prefetch" href="/assets/js/46.4e18b7fe.js"><link rel="prefetch" href="/assets/js/47.c1dba008.js"><link rel="prefetch" href="/assets/js/48.da57593b.js"><link rel="prefetch" href="/assets/js/49.8e699822.js"><link rel="prefetch" href="/assets/js/5.21b79be3.js"><link rel="prefetch" href="/assets/js/50.697ac881.js"><link rel="prefetch" href="/assets/js/52.d137da31.js"><link rel="prefetch" href="/assets/js/53.22caaa9a.js"><link rel="prefetch" href="/assets/js/54.7f1d1532.js"><link rel="prefetch" href="/assets/js/55.40dbbf5b.js"><link rel="prefetch" href="/assets/js/56.04c24edc.js"><link rel="prefetch" href="/assets/js/57.b15918db.js"><link rel="prefetch" href="/assets/js/58.b3eb784b.js"><link rel="prefetch" href="/assets/js/59.0d462dd8.js"><link rel="prefetch" href="/assets/js/6.a2711138.js"><link rel="prefetch" href="/assets/js/60.ae65015b.js"><link rel="prefetch" href="/assets/js/61.9b15da8f.js"><link rel="prefetch" href="/assets/js/62.ca728b66.js"><link rel="prefetch" href="/assets/js/63.312b3bdd.js"><link rel="prefetch" href="/assets/js/64.56be4886.js"><link rel="prefetch" href="/assets/js/65.dff3c3a3.js"><link rel="prefetch" href="/assets/js/66.95dfff51.js"><link rel="prefetch" href="/assets/js/67.17e7a9be.js"><link rel="prefetch" href="/assets/js/68.e3b5c05a.js"><link rel="prefetch" href="/assets/js/69.9ab8c7f8.js"><link rel="prefetch" href="/assets/js/7.e9473145.js"><link rel="prefetch" href="/assets/js/70.8d72690b.js"><link rel="prefetch" href="/assets/js/71.3c25cf04.js"><link rel="prefetch" href="/assets/js/72.02b02d8d.js"><link rel="prefetch" href="/assets/js/73.2a8d2681.js"><link rel="prefetch" href="/assets/js/74.c577aba5.js"><link rel="prefetch" href="/assets/js/75.7d2617b0.js"><link rel="prefetch" href="/assets/js/76.97ad371e.js"><link rel="prefetch" href="/assets/js/77.4495b015.js"><link rel="prefetch" href="/assets/js/78.c7510b35.js"><link rel="prefetch" href="/assets/js/79.dc2b4ca2.js"><link rel="prefetch" href="/assets/js/8.fc1e2b26.js"><link rel="prefetch" href="/assets/js/80.454a982e.js"><link rel="prefetch" href="/assets/js/81.eba66eb5.js"><link rel="prefetch" href="/assets/js/82.1f34b986.js"><link rel="prefetch" href="/assets/js/83.a15e7917.js"><link rel="prefetch" href="/assets/js/84.212c8551.js"><link rel="prefetch" href="/assets/js/85.c077f397.js"><link rel="prefetch" href="/assets/js/86.70192242.js"><link rel="prefetch" href="/assets/js/87.e53f7254.js"><link rel="prefetch" href="/assets/js/88.d2f28869.js"><link rel="prefetch" href="/assets/js/89.9b4c13ce.js"><link rel="prefetch" href="/assets/js/9.a7fc3cc9.js"><link rel="prefetch" href="/assets/js/90.af82565a.js"><link rel="prefetch" href="/assets/js/91.153dc863.js"><link rel="prefetch" href="/assets/js/92.ea32e690.js"><link rel="prefetch" href="/assets/js/93.4c656124.js"><link rel="prefetch" href="/assets/js/94.b2283b24.js"><link rel="prefetch" href="/assets/js/95.4ad17bba.js"><link rel="prefetch" href="/assets/js/96.4c0c4821.js"><link rel="prefetch" href="/assets/js/97.14f25834.js"><link rel="prefetch" href="/assets/js/98.92c9fd2d.js"><link rel="prefetch" href="/assets/js/99.ef340791.js">
    <link rel="stylesheet" href="/assets/css/0.styles.299736e7.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Hadoop中文网</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="https://hadoop.apache.org/releases.html" target="_blank" rel="noopener noreferrer" class="nav-link external">
  下载安装
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="/docs/" class="nav-link router-link-active">参考文档</a></div><div class="nav-item"><a href="/docs/awesome/" class="nav-link">资源教程</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="语言支持" class="dropdown-title"><span class="title">语言支持</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/language/ch.html" class="nav-link">简体中文</a></li><li class="dropdown-item"><!----> <a href="/language/en.html" class="nav-link">English</a></li></ul></div></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="https://hadoop.apache.org/releases.html" target="_blank" rel="noopener noreferrer" class="nav-link external">
  下载安装
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="/docs/" class="nav-link router-link-active">参考文档</a></div><div class="nav-item"><a href="/docs/awesome/" class="nav-link">资源教程</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="语言支持" class="dropdown-title"><span class="title">语言支持</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/language/ch.html" class="nav-link">简体中文</a></li><li class="dropdown-item"><!----> <a href="/language/en.html" class="nav-link">English</a></li></ul></div></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span></span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#public-stable-replaceable" class="sidebar-link">Public/Stable/Replaceable</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-add-array-param" class="sidebar-link">hadoopaddarray_param</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-add-classpath" class="sidebar-link">hadoopaddclasspath</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-add-client-opts" class="sidebar-link">hadoopaddclient_opts</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-add-colonpath" class="sidebar-link">hadoopaddcolonpath</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-add-javalibpath" class="sidebar-link">hadoopaddjavalibpath</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-add-ldlibpath" class="sidebar-link">hadoopaddldlibpath</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-add-param" class="sidebar-link">hadoopaddparam</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-add-profile" class="sidebar-link">hadoopaddprofile</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-array-contains" class="sidebar-link">hadooparraycontains</a></li></ul></li><li><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#returns-0-yes" class="sidebar-link">@returns 0 = yes</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#returns-1-no" class="sidebar-link">@returns 1 = no</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-build-custom-subcmd-var" class="sidebar-link">hadoopbuildcustomsubcmdvar</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-deprecate-envvar" class="sidebar-link">hadoopdeprecateenvvar</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-detect-priv-subcmd" class="sidebar-link">hadoopdetectpriv_subcmd</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-java-exec" class="sidebar-link">hadoopjavaexec</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-java-setup" class="sidebar-link">hadoopjavasetup</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-mkdir" class="sidebar-link">hadoop_mkdir</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-need-reexec" class="sidebar-link">hadoopneedreexec</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-os-tricks" class="sidebar-link">hadoopostricks</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-sort-array" class="sidebar-link">hadoopsortarray</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-status-daemon" class="sidebar-link">hadoopstatusdaemon</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-stop-daemon" class="sidebar-link">hadoopstopdaemon</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-stop-secure-daemon" class="sidebar-link">hadoopstopsecure_daemon</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-subcommand-secure-opts" class="sidebar-link">hadoopsubcommandsecure_opts</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-translate-cygwin-path" class="sidebar-link">hadooptranslatecygwin_path</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-using-envvar" class="sidebar-link">hadoopusingenvvar</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-validate-classname" class="sidebar-link">hadoopvalidateclassname</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-verify-confdir" class="sidebar-link">hadoopverifyconfdir</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-verify-user-perm" class="sidebar-link">hadoopverifyuser_perm</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-verify-user-resolves" class="sidebar-link">hadoopverifyuser_resolves</a></li></ul></li><li><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#public-stable-not-replaceable" class="sidebar-link">Public/Stable/Not Replaceable</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-abs" class="sidebar-link">hadoop_abs</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-add-entry" class="sidebar-link">hadoopaddentry</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-debug" class="sidebar-link">hadoop_debug</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-delete-entry" class="sidebar-link">hadoopdeleteentry</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-error" class="sidebar-link">hadoop_error</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-exit-with-usage" class="sidebar-link">hadoopexitwith_usage</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-populate-workers-file" class="sidebar-link">hadooppopulateworkers_file</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-rotate-log" class="sidebar-link">hadooprotatelog</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-verify-entry" class="sidebar-link">hadoopverifyentry</a></li></ul></li><li><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#public-evolving-replaceable" class="sidebar-link">Public/Evolving/Replaceable</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-subcommand-opts" class="sidebar-link">hadoopsubcommandopts</a></li></ul></li><li><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#private-evolving-replaceable" class="sidebar-link">Private/Evolving/Replaceable</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-actual-ssh" class="sidebar-link">hadoopactualssh</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-add-common-to-classpath" class="sidebar-link">hadoopaddcommontoclasspath</a></li></ul></li><li><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#returns-1-on-failure-may-exit" class="sidebar-link">@returns 1 on failure, may exit</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#returns-0-on-success" class="sidebar-link">@returns 0 on success</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-add-to-classpath-tools" class="sidebar-link">hadoopaddtoclasspathtools</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-add-to-classpath-userpath" class="sidebar-link">hadoopaddtoclasspathuserpath</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-common-worker-mode-execute" class="sidebar-link">hadoopcommonworkermodeexecute</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-connect-to-hosts" class="sidebar-link">hadoopconnectto_hosts</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-connect-to-hosts-without-pdsh" class="sidebar-link">hadoopconnecttohostswithout_pdsh</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-daemon-handler" class="sidebar-link">hadoopdaemonhandler</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-do-classpath-subcommand" class="sidebar-link">hadoopdoclasspath_subcommand</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-exec-hadooprc" class="sidebar-link">hadoopexechadooprc</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-exec-user-hadoopenv" class="sidebar-link">hadoopexecuser_hadoopenv</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-finalize" class="sidebar-link">hadoop_finalize</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-finalize-classpath" class="sidebar-link">hadoopfinalizeclasspath</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-finalize-hadoop-heap" class="sidebar-link">hadoopfinalizehadoop_heap</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-finalize-hadoop-opts" class="sidebar-link">hadoopfinalizehadoop_opts</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-finalize-libpaths" class="sidebar-link">hadoopfinalizelibpaths</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-generic-java-subcmd-handler" class="sidebar-link">hadoopgenericjavasubcmdhandler</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-import-shellprofiles" class="sidebar-link">hadoopimportshellprofiles</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-parse-args" class="sidebar-link">hadoopparseargs</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-privilege-check" class="sidebar-link">hadoopprivilegecheck</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-secure-daemon-handler" class="sidebar-link">hadoopsecuredaemon_handler</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-setup-secure-service" class="sidebar-link">hadoopsetupsecure_service</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-shellprofiles-classpath" class="sidebar-link">hadoopshellprofilesclasspath</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-shellprofiles-finalize" class="sidebar-link">hadoopshellprofilesfinalize</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-shellprofiles-init" class="sidebar-link">hadoopshellprofilesinit</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-shellprofiles-nativelib" class="sidebar-link">hadoopshellprofilesnativelib</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-start-daemon" class="sidebar-link">hadoopstartdaemon</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-start-daemon-wrapper" class="sidebar-link">hadoopstartdaemon_wrapper</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-start-secure-daemon" class="sidebar-link">hadoopstartsecure_daemon</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-start-secure-daemon-wrapper" class="sidebar-link">hadoopstartsecuredaemonwrapper</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-su" class="sidebar-link">hadoop_su</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-verify-logdir" class="sidebar-link">hadoopverifylogdir</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-verify-piddir" class="sidebar-link">hadoopverifypiddir</a></li><li class="sidebar-sub-header"><a href="/docs/hadoop-project-dist/hadoop-common/UnixShellAPI.html#hadoop-verify-secure-prereq" class="sidebar-link">hadoopverifysecure_prereq</a></li></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><ul><li>Public/Stable/Replaceable
<ul><li>hadoop_add_array_param</li> <li>hadoop_add_classpath</li> <li>hadoop_add_client_opts</li> <li>hadoop_add_colonpath</li> <li>hadoop_add_javalibpath</li> <li>hadoop_add_ldlibpath</li> <li>hadoop_add_param</li> <li>hadoop_add_profile</li> <li>hadoop_array_contains</li> <li>hadoop_build_custom_subcmd_var</li> <li>hadoop_deprecate_envvar</li> <li>hadoop_detect_priv_subcmd</li> <li>hadoop_java_exec</li> <li>hadoop_java_setup</li> <li>hadoop_mkdir</li> <li>hadoop_need_reexec</li> <li>hadoop_os_tricks</li> <li>hadoop_sort_array</li> <li>hadoop_status_daemon</li> <li>hadoop_stop_daemon</li> <li>hadoop_stop_secure_daemon</li> <li>hadoop_subcommand_secure_opts</li> <li>hadoop_translate_cygwin_path</li> <li>hadoop_using_envvar</li> <li>hadoop_validate_classname</li> <li>hadoop_verify_confdir</li> <li>hadoop_verify_user_perm</li> <li>hadoop_verify_user_resolves</li></ul></li> <li>Public/Stable/Not Replaceable
<ul><li>hadoop_abs</li> <li>hadoop_add_entry</li> <li>hadoop_debug</li> <li>hadoop_delete_entry</li> <li>hadoop_error</li> <li>hadoop_exit_with_usage</li> <li>hadoop_populate_workers_file</li> <li>hadoop_rotate_log</li> <li>hadoop_verify_entry</li></ul></li> <li>Public/Evolving/Replaceable
<ul><li>hadoop_subcommand_opts</li></ul></li> <li>Private/Evolving/Replaceable
<ul><li>hadoop_actual_ssh</li> <li>hadoop_add_common_to_classpath</li> <li>hadoop_add_to_classpath_tools</li> <li>hadoop_add_to_classpath_userpath</li> <li>hadoop_common_worker_mode_execute</li> <li>hadoop_connect_to_hosts</li> <li>hadoop_connect_to_hosts_without_pdsh</li> <li>hadoop_daemon_handler</li> <li>hadoop_do_classpath_subcommand</li> <li>hadoop_exec_hadooprc</li> <li>hadoop_exec_user_hadoopenv</li> <li>hadoop_finalize</li> <li>hadoop_finalize_classpath</li> <li>hadoop_finalize_hadoop_heap</li> <li>hadoop_finalize_hadoop_opts</li> <li>hadoop_finalize_libpaths</li> <li>hadoop_generic_java_subcmd_handler</li> <li>hadoop_import_shellprofiles</li> <li>hadoop_parse_args</li> <li>hadoop_privilege_check</li> <li>hadoop_secure_daemon_handler</li> <li>hadoop_setup_secure_service</li> <li>hadoop_shellprofiles_classpath</li> <li>hadoop_shellprofiles_finalize</li> <li>hadoop_shellprofiles_init</li> <li>hadoop_shellprofiles_nativelib</li> <li>hadoop_start_daemon</li> <li>hadoop_start_daemon_wrapper</li> <li>hadoop_start_secure_daemon</li> <li>hadoop_start_secure_daemon_wrapper</li> <li>hadoop_su</li> <li>hadoop_verify_logdir</li> <li>hadoop_verify_piddir</li> <li>hadoop_verify_secure_prereq</li></ul></li></ul> <hr> <h2 id="public-stable-replaceable"><a href="#public-stable-replaceable" class="header-anchor">#</a> Public/Stable/Replaceable</h2> <h3 id="hadoop-add-array-param"><a href="#hadoop-add-array-param" class="header-anchor">#</a> hadoop_add_array_param</h3> <ul><li><p>Synopsis</p> <p>hadoop_add_array_param envvar appendstring</p></li> <li><p>Description</p></li></ul> <p>Add the appendstring if checkstring is not present in the given array</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-add-classpath"><a href="#hadoop-add-classpath" class="header-anchor">#</a> hadoop_add_classpath</h3> <ul><li><p>Synopsis</p> <p>hadoop_add_classpath object [before|after]</p></li> <li><p>Description</p></li></ul> <p>Add a file system object (directory, file, wildcard, …) to the classpath. Optionally provide a hint as to where in the classpath it should go.</p> <ul><li>Returns</li></ul> <p>0 = success (added or duplicate)</p> <p>1 = failure (doesn’t exist or some other reason)</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-add-client-opts"><a href="#hadoop-add-client-opts" class="header-anchor">#</a> hadoop_add_client_opts</h3> <ul><li><p>Synopsis</p> <p>hadoop_add_client_opts</p></li> <li><p>Description</p></li></ul> <p>Adds the HADOOP_CLIENT_OPTS variable to HADOOP_OPTS if HADOOP_SUBCMD_SUPPORTDAEMONIZATION is false</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-add-colonpath"><a href="#hadoop-add-colonpath" class="header-anchor">#</a> hadoop_add_colonpath</h3> <ul><li><p>Synopsis</p> <p>hadoop_add_colonpath envvar object [before|after]</p></li> <li><p>Description</p></li></ul> <p>Add a file system object (directory, file, wildcard, …) to the colonpath. Optionally provide a hint as to where in the colonpath it should go. Prior to adding, objects are checked for duplication and check for existence. Many other functions use this function as their base implementation including hadoop_add_javalibpath and hadoop_add_ldlibpath.</p> <ul><li>Returns</li></ul> <p>0 = success (added or duplicate)</p> <p>1 = failure (doesn’t exist or some other reason)</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-add-javalibpath"><a href="#hadoop-add-javalibpath" class="header-anchor">#</a> hadoop_add_javalibpath</h3> <ul><li><p>Synopsis</p> <p>hadoop_add_javalibpath object [before|after]</p></li> <li><p>Description</p></li></ul> <p>Add a file system object (directory, file, wildcard, …) to the Java JNI path. Optionally provide a hint as to where in the Java JNI path it should go.</p> <ul><li>Returns</li></ul> <p>0 = success (added or duplicate)</p> <p>1 = failure (doesn’t exist or some other reason)</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-add-ldlibpath"><a href="#hadoop-add-ldlibpath" class="header-anchor">#</a> hadoop_add_ldlibpath</h3> <ul><li><p>Synopsis</p> <p>hadoop_add_ldlibpath object [before|after]</p></li> <li><p>Description</p></li></ul> <p>Add a file system object (directory, file, wildcard, …) to the LD_LIBRARY_PATH. Optionally provide a hint as to where in the LD_LIBRARY_PATH it should go.</p> <ul><li>Returns</li></ul> <p>0 = success (added or duplicate)</p> <p>1 = failure (doesn’t exist or some other reason)</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-add-param"><a href="#hadoop-add-param" class="header-anchor">#</a> hadoop_add_param</h3> <ul><li><p>Synopsis</p> <p>hadoop_add_param envvar checkstring appendstring</p></li> <li><p>Description</p></li></ul> <p>Append the appendstring if checkstring is not present in the given envvar</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-add-profile"><a href="#hadoop-add-profile" class="header-anchor">#</a> hadoop_add_profile</h3> <ul><li><p>Synopsis</p> <p>hadoop_add_profile shellprofile</p></li> <li><p>Description</p></li></ul> <p>Register the given shellprofile to the Hadoop shell subsystem</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-array-contains"><a href="#hadoop-array-contains" class="header-anchor">#</a> hadoop_array_contains</h3> <ul><li><p>Synopsis</p> <p>hadoop_array_contains element array</p></li> <li><p>Description</p></li></ul> <p>Check if an array has a given value</p> <ul><li>Returns</li></ul> <h2 id="returns-0-yes"><a href="#returns-0-yes" class="header-anchor">#</a> @returns 0 = yes</h2> <h2 id="returns-1-no"><a href="#returns-1-no" class="header-anchor">#</a> @returns 1 = no</h2> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-build-custom-subcmd-var"><a href="#hadoop-build-custom-subcmd-var" class="header-anchor">#</a> hadoop_build_custom_subcmd_var</h3> <ul><li><p>Synopsis</p> <p>hadoop_build_custom_subcmd_var command subcommand customid</p></li> <li><p>Description</p></li></ul> <p>Build custom subcommand var</p> <ul><li>Returns</li></ul> <p>string</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-deprecate-envvar"><a href="#hadoop-deprecate-envvar" class="header-anchor">#</a> hadoop_deprecate_envvar</h3> <ul><li><p>Synopsis</p> <p>hadoop_deprecate_envvar oldvar newvar</p></li> <li><p>Description</p></li></ul> <p>Replace oldvar with newvar if oldvar exists.</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-detect-priv-subcmd"><a href="#hadoop-detect-priv-subcmd" class="header-anchor">#</a> hadoop_detect_priv_subcmd</h3> <ul><li><p>Synopsis</p> <p>hadoop_detect_priv_subcmd command subcommand</p></li> <li><p>Description</p></li></ul> <p>autodetect whether this is a priv subcmd by whether or not a priv user var exists and if HADOOP_SECURE_CLASSNAME is defined</p> <ul><li>Returns</li></ul> <p>1 = not priv</p> <p>0 = priv</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-java-exec"><a href="#hadoop-java-exec" class="header-anchor">#</a> hadoop_java_exec</h3> <ul><li><p>Synopsis</p> <p>hadoop_java_exec command class [options]</p></li> <li><p>Description</p></li></ul> <p>Execute the Java class, passing along any options. Additionally, set the Java property -Dproc_command.</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-java-setup"><a href="#hadoop-java-setup" class="header-anchor">#</a> hadoop_java_setup</h3> <ul><li><p>Synopsis</p> <p>hadoop_java_setup</p></li> <li><p>Description</p></li></ul> <p>Configure/verify ${JAVA_HOME}</p> <ul><li>Returns</li></ul> <p>may exit on failure conditions</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-mkdir"><a href="#hadoop-mkdir" class="header-anchor">#</a> hadoop_mkdir</h3> <ul><li><p>Synopsis</p> <p>hadoop_mkdir dir</p></li> <li><p>Description</p></li></ul> <p>Create the directory ‘dir’.</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-need-reexec"><a href="#hadoop-need-reexec" class="header-anchor">#</a> hadoop_need_reexec</h3> <ul><li><p>Synopsis</p> <p>hadoop_need_reexec subcommand</p></li> <li><p>Description</p></li></ul> <p>Verify that ${USER} is allowed to execute the given subcommand.</p> <ul><li>Returns</li></ul> <p>1 on no re-exec needed</p> <p>0 on need to re-exec</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-os-tricks"><a href="#hadoop-os-tricks" class="header-anchor">#</a> hadoop_os_tricks</h3> <ul><li><p>Synopsis</p> <p>hadoop_os_tricks</p></li> <li><p>Description</p></li></ul> <p>Routine to configure any OS-specific settings.</p> <ul><li>Returns</li></ul> <p>may exit on failure conditions</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-sort-array"><a href="#hadoop-sort-array" class="header-anchor">#</a> hadoop_sort_array</h3> <ul><li><p>Synopsis</p> <p>hadoop_sort_array arrayvar</p></li> <li><p>Description</p></li></ul> <p>Sort an array (must not contain regexps) present in the given array</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-status-daemon"><a href="#hadoop-status-daemon" class="header-anchor">#</a> hadoop_status_daemon</h3> <ul><li><p>Synopsis</p> <p>hadoop_status_daemon pidfile</p></li> <li><p>Description</p></li></ul> <p>Determine the status of the daemon referenced by pidfile</p> <ul><li>Returns</li></ul> <p>(mostly) LSB 4.1.0 compatible status</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-stop-daemon"><a href="#hadoop-stop-daemon" class="header-anchor">#</a> hadoop_stop_daemon</h3> <ul><li><p>Synopsis</p> <p>hadoop_stop_daemon command pidfile</p></li> <li><p>Description</p></li></ul> <p>Stop the non-privileged command daemon with that that is running at pidfile.</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-stop-secure-daemon"><a href="#hadoop-stop-secure-daemon" class="header-anchor">#</a> hadoop_stop_secure_daemon</h3> <ul><li><p>Synopsis</p> <p>hadoop_stop_secure_daemon command daemonpidfile wrapperpidfile</p></li> <li><p>Description</p></li></ul> <p>Stop the privileged command daemon with that that is running at daemonpidfile and launched with the wrapper at wrapperpidfile.</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-subcommand-secure-opts"><a href="#hadoop-subcommand-secure-opts" class="header-anchor">#</a> hadoop_subcommand_secure_opts</h3> <ul><li><p>Synopsis</p> <p>hadoop_subcommand_secure_opts program subcommand</p></li> <li><p>Description</p></li></ul> <p>Add custom (program)_(command)_SECURE_EXTRA_OPTS to HADOOP_OPTS. This does not handle the pre-3.x deprecated cases</p> <ul><li>Returns</li></ul> <p>will exit on failure conditions</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-translate-cygwin-path"><a href="#hadoop-translate-cygwin-path" class="header-anchor">#</a> hadoop_translate_cygwin_path</h3> <ul><li><p>Synopsis</p> <p>hadoop_translate_cygwin_path varnameref [true]</p></li> <li><p>Description</p></li></ul> <p>Converts the contents of the variable name varnameref into the equivalent Windows path. If the second parameter is true, then varnameref is treated as though it was a path list.</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-using-envvar"><a href="#hadoop-using-envvar" class="header-anchor">#</a> hadoop_using_envvar</h3> <ul><li><p>Synopsis</p> <p>hadoop_using_envvar var</p></li> <li><p>Description</p></li></ul> <p>Declare var being used and print its value.</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-validate-classname"><a href="#hadoop-validate-classname" class="header-anchor">#</a> hadoop_validate_classname</h3> <ul><li><p>Synopsis</p> <p>hadoop_validate_classname classname</p></li> <li><p>Description</p></li></ul> <p>Verify that a shell command was passed a valid class name</p> <ul><li>Returns</li></ul> <p>0 = success</p> <p>1 = failure w/user message</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-verify-confdir"><a href="#hadoop-verify-confdir" class="header-anchor">#</a> hadoop_verify_confdir</h3> <ul><li><p>Synopsis</p> <p>hadoop_verify_confdir</p></li> <li><p>Description</p></li></ul> <p>Validate ${HADOOP_CONF_DIR}</p> <ul><li>Returns</li></ul> <p>will exit on failure conditions</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-verify-user-perm"><a href="#hadoop-verify-user-perm" class="header-anchor">#</a> hadoop_verify_user_perm</h3> <ul><li><p>Synopsis</p> <p>hadoop_verify_user_perm command subcommand</p></li> <li><p>Description</p></li></ul> <p>Verify that ${USER} is allowed to execute the given subcommand.</p> <ul><li>Returns</li></ul> <p>return 0 on success</p> <p>exit 1 on failure</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-verify-user-resolves"><a href="#hadoop-verify-user-resolves" class="header-anchor">#</a> hadoop_verify_user_resolves</h3> <ul><li><p>Synopsis</p> <p>hadoop_verify_user_resolves userstring</p></li> <li><p>Description</p></li></ul> <p>Verify that username in a var converts to user id</p> <ul><li>Returns</li></ul> <p>0 for success</p> <p>1 for failure</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h2 id="public-stable-not-replaceable"><a href="#public-stable-not-replaceable" class="header-anchor">#</a> Public/Stable/Not Replaceable</h2> <h3 id="hadoop-abs"><a href="#hadoop-abs" class="header-anchor">#</a> hadoop_abs</h3> <ul><li><p>Synopsis</p> <p>hadoop_abs fsobj</p></li> <li><p>Description</p></li></ul> <p>Given a filename or dir, return the absolute version of it This works as an alternative to readlink, which isn’t portable.</p> <ul><li>Returns</li></ul> <p>0 success</p> <p>1 failure</p> <p>stdout abspath</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>No</td></tr></tbody></table> <h3 id="hadoop-add-entry"><a href="#hadoop-add-entry" class="header-anchor">#</a> hadoop_add_entry</h3> <ul><li><p>Synopsis</p> <p>hadoop_add_entry</p></li> <li><p>Description</p></li></ul> <p>Given variable $1 add $2 to it</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>No</td></tr></tbody></table> <h3 id="hadoop-debug"><a href="#hadoop-debug" class="header-anchor">#</a> hadoop_debug</h3> <ul><li><p>Synopsis</p> <p>hadoop_debug string</p></li> <li><p>Description</p></li></ul> <p>Print a message to stderr if –debug is turned on</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>No</td></tr></tbody></table> <h3 id="hadoop-delete-entry"><a href="#hadoop-delete-entry" class="header-anchor">#</a> hadoop_delete_entry</h3> <ul><li><p>Synopsis</p> <p>hadoop_delete_entry</p></li> <li><p>Description</p></li></ul> <p>Given variable $1 delete $2 from it</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>No</td></tr></tbody></table> <h3 id="hadoop-error"><a href="#hadoop-error" class="header-anchor">#</a> hadoop_error</h3> <ul><li><p>Synopsis</p> <p>hadoop_error string</p></li> <li><p>Description</p></li></ul> <p>Print a message to stderr</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>No</td></tr></tbody></table> <h3 id="hadoop-exit-with-usage"><a href="#hadoop-exit-with-usage" class="header-anchor">#</a> hadoop_exit_with_usage</h3> <ul><li><p>Synopsis</p> <p>hadoop_exit_with_usage exitcode</p></li> <li><p>Description</p></li></ul> <p>Print usage information and exit with the passed exitcode</p> <ul><li>Returns</li></ul> <p>This function will always exit.</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>No</td></tr></tbody></table> <h3 id="hadoop-populate-workers-file"><a href="#hadoop-populate-workers-file" class="header-anchor">#</a> hadoop_populate_workers_file</h3> <ul><li><p>Synopsis</p> <p>hadoop_populate_workers_file filename</p></li> <li><p>Description</p></li></ul> <p>Set the worker support information to the contents of filename</p> <ul><li>Returns</li></ul> <p>will exit if file does not exist</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>No</td></tr></tbody></table> <h3 id="hadoop-rotate-log"><a href="#hadoop-rotate-log" class="header-anchor">#</a> hadoop_rotate_log</h3> <ul><li><p>Synopsis</p> <p>hadoop_rotate_log filename [number]</p></li> <li><p>Description</p></li></ul> <p>Rotates the given file until number of files exist.</p> <ul><li>Returns</li></ul> <p>$? will contain last mv’s return value</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>No</td></tr></tbody></table> <h3 id="hadoop-verify-entry"><a href="#hadoop-verify-entry" class="header-anchor">#</a> hadoop_verify_entry</h3> <ul><li><p>Synopsis</p> <p>hadoop_verify_entry</p></li> <li><p>Description</p></li></ul> <p>Given variable $1 determine if $2 is in it</p> <ul><li>Returns</li></ul> <p>0 = yes, 1 = no</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Stable</td></tr> <tr><td>Replaceable</td> <td>No</td></tr></tbody></table> <h2 id="public-evolving-replaceable"><a href="#public-evolving-replaceable" class="header-anchor">#</a> Public/Evolving/Replaceable</h2> <h3 id="hadoop-subcommand-opts"><a href="#hadoop-subcommand-opts" class="header-anchor">#</a> hadoop_subcommand_opts</h3> <ul><li><p>Synopsis</p> <p>hadoop_subcommand_opts program subcommand</p></li> <li><p>Description</p></li></ul> <p>Add custom (program)_(command)_OPTS to HADOOP_OPTS. Also handles the deprecated cases from pre-3.x.</p> <ul><li>Returns</li></ul> <p>will exit on failure conditions</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Public</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h2 id="private-evolving-replaceable"><a href="#private-evolving-replaceable" class="header-anchor">#</a> Private/Evolving/Replaceable</h2> <h3 id="hadoop-actual-ssh"><a href="#hadoop-actual-ssh" class="header-anchor">#</a> hadoop_actual_ssh</h3> <ul><li><p>Synopsis</p> <p>hadoop_actual_ssh hostname command [...]</p></li> <li><p>Description</p></li></ul> <p>Via ssh, log into hostname and run command</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-add-common-to-classpath"><a href="#hadoop-add-common-to-classpath" class="header-anchor">#</a> hadoop_add_common_to_classpath</h3> <ul><li><p>Synopsis</p> <p>hadoop_add_common_to_classpath</p></li> <li><p>Description</p></li></ul> <p>Add the common/core Hadoop components to the environment</p> <ul><li>Returns</li></ul> <h2 id="returns-1-on-failure-may-exit"><a href="#returns-1-on-failure-may-exit" class="header-anchor">#</a> @returns 1 on failure, may exit</h2> <h2 id="returns-0-on-success"><a href="#returns-0-on-success" class="header-anchor">#</a> @returns 0 on success</h2> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-add-to-classpath-tools"><a href="#hadoop-add-to-classpath-tools" class="header-anchor">#</a> hadoop_add_to_classpath_tools</h3> <ul><li><p>Synopsis</p> <p>hadoop_add_to_classpath_tools module</p></li> <li><p>Description</p></li></ul> <p>Run libexec/tools/module.sh to add to the classpath environment</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-add-to-classpath-userpath"><a href="#hadoop-add-to-classpath-userpath" class="header-anchor">#</a> hadoop_add_to_classpath_userpath</h3> <ul><li><p>Synopsis</p> <p>hadoop_add_to_classpath_userpath</p></li> <li><p>Description</p></li></ul> <p>Add the user’s custom classpath settings to the environment</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-common-worker-mode-execute"><a href="#hadoop-common-worker-mode-execute" class="header-anchor">#</a> hadoop_common_worker_mode_execute</h3> <ul><li><p>Synopsis</p> <p>hadoop_common_worker_mode_execute commandarray</p></li> <li><p>Description</p></li></ul> <p>Utility routine to handle –workers mode</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-connect-to-hosts"><a href="#hadoop-connect-to-hosts" class="header-anchor">#</a> hadoop_connect_to_hosts</h3> <ul><li><p>Synopsis</p> <p>hadoop_connect_to_hosts command [...]</p></li> <li><p>Description</p></li></ul> <p>Connect to ${HADOOP_WORKERS} or ${HADOOP_WORKER_NAMES} and execute command.</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-connect-to-hosts-without-pdsh"><a href="#hadoop-connect-to-hosts-without-pdsh" class="header-anchor">#</a> hadoop_connect_to_hosts_without_pdsh</h3> <ul><li><p>Synopsis</p> <p>hadoop_connect_to_hosts_without_pdsh command [...]</p></li> <li><p>Description</p></li></ul> <p>Connect to ${HADOOP_WORKER_NAMES} and execute command under the environment which does not support pdsh.</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-daemon-handler"><a href="#hadoop-daemon-handler" class="header-anchor">#</a> hadoop_daemon_handler</h3> <ul><li><p>Synopsis</p> <p>hadoop_daemon_handler [start|stop|status|default] command class daemonpidfile daemonoutfile [options]</p></li> <li><p>Description</p></li></ul> <p>Manage a non-privileged daemon.</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-do-classpath-subcommand"><a href="#hadoop-do-classpath-subcommand" class="header-anchor">#</a> hadoop_do_classpath_subcommand</h3> <ul><li><p>Synopsis</p> <p>hadoop_do_classpath_subcommand [parameters]</p></li> <li><p>Description</p></li></ul> <p>Perform the ‘hadoop classpath’, etc subcommand with the given parameters</p> <ul><li>Returns</li></ul> <p>will print &amp; exit with no params</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-exec-hadooprc"><a href="#hadoop-exec-hadooprc" class="header-anchor">#</a> hadoop_exec_hadooprc</h3> <ul><li><p>Synopsis</p> <p>hadoop_exec_hadooprc</p></li> <li><p>Description</p></li></ul> <p>Read the user’s settings. This provides for users to run Hadoop Shell API after system bootstrap</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-exec-user-hadoopenv"><a href="#hadoop-exec-user-hadoopenv" class="header-anchor">#</a> hadoop_exec_user_hadoopenv</h3> <ul><li><p>Synopsis</p> <p>hadoop_exec_user_hadoopenv</p></li> <li><p>Description</p></li></ul> <p>Read the user’s settings. This provides for users to override and/or append hadoop-env.sh. It is not meant as a complete system override.</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-finalize"><a href="#hadoop-finalize" class="header-anchor">#</a> hadoop_finalize</h3> <ul><li><p>Synopsis</p> <p>hadoop_finalize</p></li> <li><p>Description</p></li></ul> <p>Finish all the remaining environment settings prior to executing Java. This is a wrapper that calls the other finalize routines.</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-finalize-classpath"><a href="#hadoop-finalize-classpath" class="header-anchor">#</a> hadoop_finalize_classpath</h3> <ul><li><p>Synopsis</p> <p>hadoop_finalize_classpath</p></li> <li><p>Description</p></li></ul> <p>Finish Java classpath prior to execution</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-finalize-hadoop-heap"><a href="#hadoop-finalize-hadoop-heap" class="header-anchor">#</a> hadoop_finalize_hadoop_heap</h3> <ul><li><p>Synopsis</p> <p>hadoop_finalize_hadoop_heap</p></li> <li><p>Description</p></li></ul> <p>Finish Java heap parameters prior to execution</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-finalize-hadoop-opts"><a href="#hadoop-finalize-hadoop-opts" class="header-anchor">#</a> hadoop_finalize_hadoop_opts</h3> <ul><li><p>Synopsis</p> <p>hadoop_finalize_hadoop_opts</p></li> <li><p>Description</p></li></ul> <p>Finish configuring Hadoop specific system properties prior to executing Java</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-finalize-libpaths"><a href="#hadoop-finalize-libpaths" class="header-anchor">#</a> hadoop_finalize_libpaths</h3> <ul><li><p>Synopsis</p> <p>hadoop_finalize_libpaths</p></li> <li><p>Description</p></li></ul> <p>Finish Java JNI paths prior to execution</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-generic-java-subcmd-handler"><a href="#hadoop-generic-java-subcmd-handler" class="header-anchor">#</a> hadoop_generic_java_subcmd_handler</h3> <ul><li><p>Synopsis</p> <p>hadoop_generic_java_subcmd_handler</p></li> <li><p>Description</p></li></ul> <p>Handle subcommands from main program entries</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-import-shellprofiles"><a href="#hadoop-import-shellprofiles" class="header-anchor">#</a> hadoop_import_shellprofiles</h3> <ul><li><p>Synopsis</p> <p>hadoop_import_shellprofiles</p></li> <li><p>Description</p></li></ul> <p>Import shellprofile.d content</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-parse-args"><a href="#hadoop-parse-args" class="header-anchor">#</a> hadoop_parse_args</h3> <ul><li><p>Synopsis</p> <p>hadoop_parse_args [parameters, typically &quot;$@&quot;]</p></li> <li><p>Description</p></li></ul> <p>generic shell script opton parser. sets HADOOP_PARSE_COUNTER to set number the caller should shift</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-privilege-check"><a href="#hadoop-privilege-check" class="header-anchor">#</a> hadoop_privilege_check</h3> <ul><li><p>Synopsis</p> <p>hadoop_privilege_check</p></li> <li><p>Description</p></li></ul> <p>Check if we are running with priv by default, this implementation looks for EUID=0. For OSes that have true priv separation, this should be something more complex</p> <ul><li>Returns</li></ul> <p>1 = no priv</p> <p>0 = priv</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-secure-daemon-handler"><a href="#hadoop-secure-daemon-handler" class="header-anchor">#</a> hadoop_secure_daemon_handler</h3> <ul><li><p>Synopsis</p> <p>hadoop_secure_daemon_handler [start|stop|status|default] command class daemonpidfile daemonoutfile wrapperpidfile wrapperoutfile wrappererrfile [options]</p></li> <li><p>Description</p></li></ul> <p>Manage a privileged daemon.</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-setup-secure-service"><a href="#hadoop-setup-secure-service" class="header-anchor">#</a> hadoop_setup_secure_service</h3> <ul><li><p>Synopsis</p> <p>hadoop_setup_secure_service</p></li> <li><p>Description</p></li></ul> <p>None</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-shellprofiles-classpath"><a href="#hadoop-shellprofiles-classpath" class="header-anchor">#</a> hadoop_shellprofiles_classpath</h3> <ul><li><p>Synopsis</p> <p>hadoop_shellprofiles_classpath</p></li> <li><p>Description</p></li></ul> <p>Apply the shell profile classpath additions</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-shellprofiles-finalize"><a href="#hadoop-shellprofiles-finalize" class="header-anchor">#</a> hadoop_shellprofiles_finalize</h3> <ul><li><p>Synopsis</p> <p>hadoop_shellprofiles_finalize</p></li> <li><p>Description</p></li></ul> <p>Apply the shell profile final configuration</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-shellprofiles-init"><a href="#hadoop-shellprofiles-init" class="header-anchor">#</a> hadoop_shellprofiles_init</h3> <ul><li><p>Synopsis</p> <p>hadoop_shellprofiles_init</p></li> <li><p>Description</p></li></ul> <p>Initialize the registered shell profiles</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-shellprofiles-nativelib"><a href="#hadoop-shellprofiles-nativelib" class="header-anchor">#</a> hadoop_shellprofiles_nativelib</h3> <ul><li><p>Synopsis</p> <p>hadoop_shellprofiles_nativelib</p></li> <li><p>Description</p></li></ul> <p>Apply the shell profile native library additions</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-start-daemon"><a href="#hadoop-start-daemon" class="header-anchor">#</a> hadoop_start_daemon</h3> <ul><li><p>Synopsis</p> <p>hadoop_start_daemon command class pidfile [options]</p></li> <li><p>Description</p></li></ul> <p>Start a non-privileged daemon in the foreground.</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-start-daemon-wrapper"><a href="#hadoop-start-daemon-wrapper" class="header-anchor">#</a> hadoop_start_daemon_wrapper</h3> <ul><li><p>Synopsis</p> <p>hadoop_start_daemon_wrapper command class pidfile outfile [options]</p></li> <li><p>Description</p></li></ul> <p>Start a non-privileged daemon in the background.</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-start-secure-daemon"><a href="#hadoop-start-secure-daemon" class="header-anchor">#</a> hadoop_start_secure_daemon</h3> <ul><li><p>Synopsis</p> <p>hadoop_start_secure_daemon command class daemonpidfile daemonoutfile daemonerrfile wrapperpidfile [options]</p></li> <li><p>Description</p></li></ul> <p>Start a privileged daemon in the foreground.</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-start-secure-daemon-wrapper"><a href="#hadoop-start-secure-daemon-wrapper" class="header-anchor">#</a> hadoop_start_secure_daemon_wrapper</h3> <ul><li><p>Synopsis</p> <p>hadoop_start_secure_daemon_wrapper command class daemonpidfile daemonoutfile wrapperpidfile warpperoutfile daemonerrfile [options]</p></li> <li><p>Description</p></li></ul> <p>Start a privileged daemon in the background.</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-su"><a href="#hadoop-su" class="header-anchor">#</a> hadoop_su</h3> <ul><li><p>Synopsis</p> <p>hadoop_su user commandstring</p></li> <li><p>Description</p></li></ul> <p>Execute a command via su when running as root if the given user is found or exit with failure if not. otherwise just run it. (This is intended to be used by the start-/stop- scripts.)</p> <ul><li>Returns</li></ul> <p>exitstatus</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-verify-logdir"><a href="#hadoop-verify-logdir" class="header-anchor">#</a> hadoop_verify_logdir</h3> <ul><li><p>Synopsis</p> <p>hadoop_verify_logdir</p></li> <li><p>Description</p></li></ul> <p>None</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-verify-piddir"><a href="#hadoop-verify-piddir" class="header-anchor">#</a> hadoop_verify_piddir</h3> <ul><li><p>Synopsis</p> <p>hadoop_verify_piddir</p></li> <li><p>Description</p></li></ul> <p>None</p> <ul><li>Returns</li></ul> <p>Nothing</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table> <h3 id="hadoop-verify-secure-prereq"><a href="#hadoop-verify-secure-prereq" class="header-anchor">#</a> hadoop_verify_secure_prereq</h3> <ul><li><p>Synopsis</p> <p>hadoop_verify_secure_prereq</p></li> <li><p>Description</p></li></ul> <p>Verify that prerequisites have been met prior to excuting a privileged program.</p> <ul><li>Returns</li></ul> <p>This routine may exit.</p> <table><thead><tr><th>Classification</th> <th>Level</th></tr></thead> <tbody><tr><td>Audience</td> <td>Private</td></tr> <tr><td>Stability</td> <td>Evolving</td></tr> <tr><td>Replaceable</td> <td>Yes</td></tr></tbody></table></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.44e5c4e8.js" defer></script><script src="/assets/js/2.fd33e103.js" defer></script><script src="/assets/js/51.6c32c16e.js" defer></script>
  </body>
</html>
